{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom functools import partial\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nimport tempfile\nimport matplotlib.pyplot as plt\n\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:06:53.047341Z","iopub.execute_input":"2023-02-03T11:06:53.047852Z","iopub.status.idle":"2023-02-03T11:07:06.404754Z","shell.execute_reply.started":"2023-02-03T11:06:53.047761Z","shell.execute_reply":"2023-02-03T11:07:06.403668Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2023-02-03 11:06:53.867635: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2023-02-03 11:06:53.867824: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"},{"name":"stdout","text":"Device: grpc://10.0.0.2:8470\n","output_type":"stream"},{"name":"stderr","text":"2023-02-03 11:07:00.884767: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2023-02-03 11:07:00.887358: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2023-02-03 11:07:00.887398: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2023-02-03 11:07:00.887421: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (55cd33250aa8): /proc/driver/nvidia/version does not exist\n2023-02-03 11:07:00.890166: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-03 11:07:00.891524: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2023-02-03 11:07:00.896963: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2023-02-03 11:07:00.920279: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2023-02-03 11:07:00.920335: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n2023-02-03 11:07:00.938603: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2023-02-03 11:07:00.938663: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n2023-02-03 11:07:00.940346: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30020\n","output_type":"stream"},{"name":"stdout","text":"Number of replicas: 8\n2.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"#Helps optimise the performace of data loading and preprocessing as it allows tensorflow to process data in parallel\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n#this is the path to get the dataset which is located in Google Cloud Storage\nGCS_PATH = KaggleDatasets().get_gcs_path()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [1024, 1024]\nIMAGE_RESIZE = [256, 256]","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:07:06.407084Z","iopub.execute_input":"2023-02-03T11:07:06.407407Z","iopub.status.idle":"2023-02-03T11:07:06.743304Z","shell.execute_reply.started":"2023-02-03T11:07:06.407373Z","shell.execute_reply":"2023-02-03T11:07:06.742732Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"trainingRecords, validationRecords = train_test_split(\n    #returns a list of files matching the given pattern\n    tf.io.gfile.glob(GCS_PATH + '/tfrecords/train*.tfrec'),\n    test_size=0.1, random_state=5 \n)\ntestRecords = tf.io.gfile.glob(GCS_PATH + '/tfrecords/test*.tfrec')\nprint('Train TFRecord Files:', len(trainingRecords))\nprint('Validation TFRecord Files:', len(validationRecords))\nprint('Test TFRecord Files:', len(testRecords))","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:07:06.744748Z","iopub.execute_input":"2023-02-03T11:07:06.744995Z","iopub.status.idle":"2023-02-03T11:07:06.876755Z","shell.execute_reply.started":"2023-02-03T11:07:06.744963Z","shell.execute_reply":"2023-02-03T11:07:06.875566Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Train TFRecord Files: 14\nValidation TFRecord Files: 2\nTest TFRecord Files: 16\n","output_type":"stream"},{"name":"stderr","text":"2023-02-03 11:07:06.753053: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n2023-02-03 11:07:06.828202: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We need to know convert the images to tensors ( Tensors are similar to matrices and can have a specific shape and dimensionality)","metadata":{}},{"cell_type":"code","source":"def transformAndNormalise(img):\n    #image is transformed to RGB\n    img = tf.image.decode_jpeg(img,channels=3)\n    #Image is normalised\n    img = tf.cast(img,tf.float32)/255\n    #Reshaping the tensor\n    img = tf.reshape(img,[*IMAGE_SIZE, 3])\n    return img\n    ","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:08:14.431853Z","iopub.execute_input":"2023-02-03T11:08:14.432279Z","iopub.status.idle":"2023-02-03T11:08:14.440034Z","shell.execute_reply.started":"2023-02-03T11:08:14.432236Z","shell.execute_reply":"2023-02-03T11:08:14.438821Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def readTFRecord(example,labeled):\n    #Defines the format of the data stored in TFRecord\n    tfrecord_format = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64)\n    } if labeled else {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = transformAndNormalise(example['image'])\n    if labeled:\n        #if labelled return image and target as tuble\n        label = tf.cast(example['target'], tf.int32)\n        return image, tf.cast(label, tf.float32)\n    # if not labeled return iamge and image names as tuple\n    idNumber = example['image_name']\n    return image, idNumber","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:08:23.713987Z","iopub.execute_input":"2023-02-03T11:08:23.714294Z","iopub.status.idle":"2023-02-03T11:08:23.721378Z","shell.execute_reply.started":"2023-02-03T11:08:23.714263Z","shell.execute_reply":"2023-02-03T11:08:23.720225Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def loadDataset(filenames,labeled=True, ordered = False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(partial(readTFRecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:10:39.590993Z","iopub.execute_input":"2023-02-03T11:10:39.591250Z","iopub.status.idle":"2023-02-03T11:10:39.597909Z","shell.execute_reply.started":"2023-02-03T11:10:39.591223Z","shell.execute_reply":"2023-02-03T11:10:39.596481Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def dataAugmentation(image, label):\n    # Adds a bit of noise to the images to increase model robustness\n    image = tf.image.random_jpeg_quality(image,75,95)\n    #Will randomly brighten and dim the image\n    image = tf.image.random_brightness(image,0.3)\n    #Flip image horizontally randomly\n    image = tf.image.random_flip_left_right(image)\n    #Resize image\n    image = tf.image.resize(image, IMAGE_RESIZE)\n    \n    return image, label","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:10:42.052069Z","iopub.execute_input":"2023-02-03T11:10:42.052491Z","iopub.status.idle":"2023-02-03T11:10:42.058799Z","shell.execute_reply.started":"2023-02-03T11:10:42.052454Z","shell.execute_reply":"2023-02-03T11:10:42.057611Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def resizeImage(image, label):\n    image = tf.image.resize(image, IMAGE_RESIZE)\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:10:49.309012Z","iopub.execute_input":"2023-02-03T11:10:49.309283Z","iopub.status.idle":"2023-02-03T11:10:49.314511Z","shell.execute_reply.started":"2023-02-03T11:10:49.309254Z","shell.execute_reply":"2023-02-03T11:10:49.313545Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Returns the traing dataset\ndef get_training_dataset():\n    dataset = loadDataset(trainingRecords, labeled=True)\n    # using the map function data augmentation is applied to each image\n    dataset = dataset.map(dataAugmentation, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.repeat()\n    #shuffles the dataset randomly to avoid overfitting\n    dataset = dataset.shuffle(2048)\n    # batches the data in to specific sized groups\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:15:02.035478Z","iopub.execute_input":"2023-02-03T11:15:02.036375Z","iopub.status.idle":"2023-02-03T11:15:02.042465Z","shell.execute_reply.started":"2023-02-03T11:15:02.036319Z","shell.execute_reply":"2023-02-03T11:15:02.041446Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_validation_dataset(ordered=False):\n    dataset = loadDataset(validationRecords, labeled=True, ordered=ordered)\n    dataset = dataset.map(resizeImage, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:15:04.278673Z","iopub.execute_input":"2023-02-03T11:15:04.278923Z","iopub.status.idle":"2023-02-03T11:15:04.283903Z","shell.execute_reply.started":"2023-02-03T11:15:04.278900Z","shell.execute_reply":"2023-02-03T11:15:04.283315Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_test_dataset(ordered=False):\n    dataset = loadDataset(testRecords, labeled=False, ordered=ordered)\n    dataset = dataset.map(resizeImage, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:15:06.024246Z","iopub.execute_input":"2023-02-03T11:15:06.024761Z","iopub.status.idle":"2023-02-03T11:15:06.030281Z","shell.execute_reply.started":"2023-02-03T11:15:06.024719Z","shell.execute_reply":"2023-02-03T11:15:06.029463Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Takes the image records as input and returns the number of images in thosse records\ndef count_data_items(filenames):\n    count = 0\n    for filename in filenames:\n        match = re.search(r\"-([0-9]*)\\.\", filename)\n        count += int(match.group(1))\n    return count","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:19:37.229288Z","iopub.execute_input":"2023-02-03T11:19:37.229564Z","iopub.status.idle":"2023-02-03T11:19:37.234981Z","shell.execute_reply.started":"2023-02-03T11:19:37.229534Z","shell.execute_reply":"2023-02-03T11:19:37.233981Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#displays the number of images in each dataset\nNUM_TRAINING_IMAGES = count_data_items(trainingRecords)\nNUM_VALIDATION_IMAGES = count_data_items(validationRecords)\nNUM_TEST_IMAGES = count_data_items(testRecords)\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nprint(\n    'Dataset: {} training images, {} validation images, {} unlabeled test images'.format(\n        NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:19:39.191833Z","iopub.execute_input":"2023-02-03T11:19:39.192102Z","iopub.status.idle":"2023-02-03T11:19:39.198784Z","shell.execute_reply.started":"2023-02-03T11:19:39.192075Z","shell.execute_reply":"2023-02-03T11:19:39.197477Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Dataset: 28984 training images, 4142 validation images, 10982 unlabeled test images\n","output_type":"stream"}]},{"cell_type":"code","source":"#Reading the csv's\ntrain_csv = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\ntest_csv = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:19:41.796536Z","iopub.execute_input":"2023-02-03T11:19:41.797035Z","iopub.status.idle":"2023-02-03T11:19:41.900668Z","shell.execute_reply.started":"2023-02-03T11:19:41.797004Z","shell.execute_reply":"2023-02-03T11:19:41.899588Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# We are looking to get the disparity between malignant and benign images\ntotalImages = train_csv['target'].size\n#gets the number of total targets that are 1\nmalignant = np.count_nonzero(train_csv['target'])\n\n# the remaining are 0 values hence benign\nbenign = totalImages - malignant\n\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    totalImages, malignant, 100 * malignant / totalImages))","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:21:16.777043Z","iopub.execute_input":"2023-02-03T11:21:16.777321Z","iopub.status.idle":"2023-02-03T11:21:16.787660Z","shell.execute_reply.started":"2023-02-03T11:21:16.777292Z","shell.execute_reply":"2023-02-03T11:21:16.786011Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Examples:\n    Total: 33126\n    Positive: 584 (1.76% of total)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ensuring that the datasets are of the right shape\ntrainDataset = get_training_dataset()\nvalidationDataset = get_validation_dataset()\n\ntrainDataset.take(1)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:21:18.515605Z","iopub.execute_input":"2023-02-03T11:21:18.515940Z","iopub.status.idle":"2023-02-03T11:21:18.618960Z","shell.execute_reply.started":"2023-02-03T11:21:18.515912Z","shell.execute_reply":"2023-02-03T11:21:18.617467Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<TakeDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.float32)>"},"metadata":{}}]},{"cell_type":"code","source":"validationDataset.take(1)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:21:20.688328Z","iopub.execute_input":"2023-02-03T11:21:20.688586Z","iopub.status.idle":"2023-02-03T11:21:20.695866Z","shell.execute_reply.started":"2023-02-03T11:21:20.688559Z","shell.execute_reply":"2023-02-03T11:21:20.694842Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<TakeDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.float32)>"},"metadata":{}}]},{"cell_type":"code","source":"images, labels = next(iter(trainDataset))","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:21:27.223566Z","iopub.execute_input":"2023-02-03T11:21:27.224481Z","iopub.status.idle":"2023-02-03T11:21:40.428791Z","shell.execute_reply.started":"2023-02-03T11:21:27.224432Z","shell.execute_reply":"2023-02-03T11:21:40.427274Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.keras import backend as K\n# focal loss is a type of loss function that addresses class imbalances.\n# The loss function works by modulating the standard cross - entropy function loss by down-weighting well - classified examples and \n# up -weighting the poorly - classified examples.\ndef focal_loss(alpha=0.25, gamma=2.0):\n    def focal_crossentropy(y_true, y_pred):\n        # calculate binary cross-entropy loss\n        binary_crossentropy = K.binary_crossentropy(y_true, y_pred)\n        \n        # clip predictions to avoid log(0) error\n        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n        \n        # calculate p_t - probability of positive class\n        positive_prob = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n        \n        # calculate alpha_factor\n        alpha_factor = y_true * alpha + (1 - alpha) * (1 - y_true)\n        \n        # calculate modulating_factor\n        modulating_factor = K.pow((1 - positive_prob), gamma)\n        \n        # calculate final loss by combining alpha_factor and modulating_factor with binary_crossentropy\n        loss = K.mean(alpha_factor * modulating_factor * binary_crossentropy, axis=-1)\n        \n        return loss\n    return focal_crossentropy","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:21:47.033438Z","iopub.execute_input":"2023-02-03T11:21:47.033714Z","iopub.status.idle":"2023-02-03T11:21:47.040844Z","shell.execute_reply.started":"2023-02-03T11:21:47.033682Z","shell.execute_reply":"2023-02-03T11:21:47.039768Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa\ndef make_model(output_bias = None, metrics = None):\n    \n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n    # Creating a model with pre - trained weights from the VGG16 architecture\n    \n    base_model = tf.keras.applications.vgg16.VGG16(input_shape=(*IMAGE_RESIZE, 3),\n                                                include_top=False,\n                                                weights='imagenet')\n    #Freezing the base models weights\n    base_model.trainable = False\n    \n    #Create a new sequential model\n    model = tf.keras.Sequential([\n        # Add the base model as the first layer\n        base_model,\n        tf.keras.layers.Dense(8, activation='swish'),\n        tf.keras.layers.Flatten(),\n        # In the last dense layer we set the bias_initailizer to the output bias,\n        #which is computed as a log of the ratio of malignant to benign samples\n        # it is added to ajust the output of the model to accout for unbalanced classes.\n        tf.keras.layers.Dense(1, activation='sigmoid',\n                              bias_initializer=output_bias)\n    ])\n    \n    model.compile(optimizer='adam',\n                  loss= tfa.losses.SigmoidFocalCrossEntropy(),\n                  metrics=metrics)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:44:56.333885Z","iopub.execute_input":"2023-02-03T11:44:56.334376Z","iopub.status.idle":"2023-02-03T11:44:56.340857Z","shell.execute_reply.started":"2023-02-03T11:44:56.334341Z","shell.execute_reply":"2023-02-03T11:44:56.340245Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nVALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:44:59.216659Z","iopub.execute_input":"2023-02-03T11:44:59.217010Z","iopub.status.idle":"2023-02-03T11:44:59.221108Z","shell.execute_reply.started":"2023-02-03T11:44:59.216981Z","shell.execute_reply":"2023-02-03T11:44:59.219925Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# To better handle the class imbalance and improve the models performance, we calculate and add a inital bias to the model \ninitial_bias = np.log([malignant/benign])\ninitial_bias","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:45:00.655376Z","iopub.execute_input":"2023-02-03T11:45:00.655660Z","iopub.status.idle":"2023-02-03T11:45:00.662291Z","shell.execute_reply.started":"2023-02-03T11:45:00.655631Z","shell.execute_reply":"2023-02-03T11:45:00.661285Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"array([-4.02038586])"},"metadata":{}}]},{"cell_type":"code","source":"with strategy.scope():\n    model = make_model(output_bias = initial_bias, metrics=tf.keras.metrics.AUC(name='auc'))","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:45:03.388862Z","iopub.execute_input":"2023-02-03T11:45:03.389175Z","iopub.status.idle":"2023-02-03T11:45:04.851585Z","shell.execute_reply.started":"2023-02-03T11:45:03.389113Z","shell.execute_reply":"2023-02-03T11:45:04.850729Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#This callback function saves the best model weights whilst trainging \ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"melanoma_model4.h5\",\n                                                    save_best_only=True)\n#This callback function stops training when the validation set's accuracys stops improving\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n                                                     restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:45:05.785295Z","iopub.execute_input":"2023-02-03T11:45:05.785833Z","iopub.status.idle":"2023-02-03T11:45:05.791170Z","shell.execute_reply.started":"2023-02-03T11:45:05.785797Z","shell.execute_reply":"2023-02-03T11:45:05.789408Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def exponential_decay(initial_learning_rate, steps):\n\n    def exponential_decay_fn(epoch):\n        \n        lr = initial_learning_rate * 0.1 ** (epoch / steps)\n        return lr\n\n    return exponential_decay_fn\n\n# Define the initial learning rate and steps for decay\ninitial_learning_rate = 0.01\nsteps = 20\n\n# Create the exponential decay function\nexponential_decay_fn = exponential_decay(initial_learning_rate, steps)\n\n# Use the exponential decay function to schedule the learning rate\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:45:08.694279Z","iopub.execute_input":"2023-02-03T11:45:08.694553Z","iopub.status.idle":"2023-02-03T11:45:08.700212Z","shell.execute_reply.started":"2023-02-03T11:45:08.694527Z","shell.execute_reply":"2023-02-03T11:45:08.699304Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    trainDataset, epochs=100,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=validationDataset,\n    validation_steps=VALID_STEPS,\n    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler]\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-03T11:45:17.976426Z","iopub.execute_input":"2023-02-03T11:45:17.976731Z","iopub.status.idle":"2023-02-03T12:04:10.649827Z","shell.execute_reply.started":"2023-02-03T11:45:17.976689Z","shell.execute_reply":"2023-02-03T12:04:10.648809Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Epoch 1/100\n226/226 [==============================] - 91s 341ms/step - loss: 0.0108 - auc: 0.5609 - val_loss: 0.0082 - val_auc: 0.7587\nEpoch 2/100\n226/226 [==============================] - 70s 309ms/step - loss: 0.0085 - auc: 0.7284 - val_loss: 0.0081 - val_auc: 0.7746\nEpoch 3/100\n226/226 [==============================] - 71s 314ms/step - loss: 0.0077 - auc: 0.7631 - val_loss: 0.0078 - val_auc: 0.7861\nEpoch 4/100\n226/226 [==============================] - 72s 321ms/step - loss: 0.0079 - auc: 0.7795 - val_loss: 0.0079 - val_auc: 0.7892\nEpoch 5/100\n226/226 [==============================] - 76s 335ms/step - loss: 0.0076 - auc: 0.7934 - val_loss: 0.0075 - val_auc: 0.8067\nEpoch 6/100\n226/226 [==============================] - 86s 384ms/step - loss: 0.0074 - auc: 0.8331 - val_loss: 0.0077 - val_auc: 0.7860\nEpoch 7/100\n226/226 [==============================] - 74s 330ms/step - loss: 0.0074 - auc: 0.8366 - val_loss: 0.0079 - val_auc: 0.7924\nEpoch 8/100\n226/226 [==============================] - 78s 347ms/step - loss: 0.0071 - auc: 0.8430 - val_loss: 0.0077 - val_auc: 0.7860\nEpoch 9/100\n226/226 [==============================] - 71s 313ms/step - loss: 0.0068 - auc: 0.8566 - val_loss: 0.0078 - val_auc: 0.7924\nEpoch 10/100\n226/226 [==============================] - 73s 324ms/step - loss: 0.0067 - auc: 0.8621 - val_loss: 0.0078 - val_auc: 0.7877\nEpoch 11/100\n226/226 [==============================] - 74s 326ms/step - loss: 0.0066 - auc: 0.8776 - val_loss: 0.0079 - val_auc: 0.7805\nEpoch 12/100\n226/226 [==============================] - 72s 319ms/step - loss: 0.0068 - auc: 0.8586 - val_loss: 0.0078 - val_auc: 0.7931\nEpoch 13/100\n226/226 [==============================] - 72s 320ms/step - loss: 0.0062 - auc: 0.8802 - val_loss: 0.0077 - val_auc: 0.8000\nEpoch 14/100\n226/226 [==============================] - 73s 325ms/step - loss: 0.0064 - auc: 0.8972 - val_loss: 0.0078 - val_auc: 0.8000\nEpoch 15/100\n226/226 [==============================] - 75s 331ms/step - loss: 0.0063 - auc: 0.8896 - val_loss: 0.0078 - val_auc: 0.7913\n","output_type":"stream"}]},{"cell_type":"code","source":"# Getting the test data set and computing preditions\ntest_ds = get_test_dataset(ordered=True)\ntest_images_ds = test_ds.map(lambda image, idnum: image)\n\nprint('predicting')\n\n\n\nprobabilities = model.predict(test_images_ds)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-03T12:04:10.651575Z","iopub.execute_input":"2023-02-03T12:04:10.651966Z","iopub.status.idle":"2023-02-03T12:04:48.073954Z","shell.execute_reply.started":"2023-02-03T12:04:10.651927Z","shell.execute_reply":"2023-02-03T12:04:48.071094Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"predicting\n","output_type":"stream"},{"name":"stderr","text":"2023-02-03 12:04:48.071114: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 38852, Output num: 0\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1675425888.067590060\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 38852, Output num: 0\",\"grpc_status\":3}\n","output_type":"stream"}]},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-03T12:04:51.924400Z","iopub.execute_input":"2023-02-03T12:04:51.924894Z","iopub.status.idle":"2023-02-03T12:04:51.940734Z","shell.execute_reply.started":"2023-02-03T12:04:51.924868Z","shell.execute_reply":"2023-02-03T12:04:51.939625Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"     image_name  target\n0  ISIC_0052060       0\n1  ISIC_0052349       0\n2  ISIC_0058510       0\n3  ISIC_0073313       0\n4  ISIC_0073502       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0052060</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0052349</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0058510</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0073313</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0073502</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n\n# Unpack the id numbers from the test dataset\nid_numbers = test_ds.map(lambda image, idnum: idnum)\n\n# Unbatch the id numbers\nunbatched_ids = id_numbers.unbatch()\n\n# Get a batch of all the test images\nall_ids = next(iter(unbatched_ids.batch(NUM_TEST_IMAGES)))\n\n# Convert the batch of ids to numpy array of strings\ntest_ids = all_ids.numpy().astype('U')\n\nprint('Generating submission.csv file...')\n","metadata":{"execution":{"iopub.status.busy":"2023-02-03T12:04:53.922815Z","iopub.execute_input":"2023-02-03T12:04:53.923092Z","iopub.status.idle":"2023-02-03T12:05:01.471112Z","shell.execute_reply.started":"2023-02-03T12:04:53.923064Z","shell.execute_reply":"2023-02-03T12:05:01.470270Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Generating submission.csv file...\n","output_type":"stream"}]},{"cell_type":"code","source":"pred_df = pd.DataFrame({'image_name': test_ids, 'target': np.concatenate(probabilities)})\npred_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-03T12:10:06.065120Z","iopub.execute_input":"2023-02-03T12:10:06.065448Z","iopub.status.idle":"2023-02-03T12:10:06.089904Z","shell.execute_reply.started":"2023-02-03T12:10:06.065416Z","shell.execute_reply":"2023-02-03T12:10:06.089136Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"     image_name    target\n0  ISIC_6381819  0.064375\n1  ISIC_5583376  0.133628\n2  ISIC_6408546  0.139268\n3  ISIC_6932354  0.156253\n4  ISIC_8191278  0.125516","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_6381819</td>\n      <td>0.064375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_5583376</td>\n      <td>0.133628</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_6408546</td>\n      <td>0.139268</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_6932354</td>\n      <td>0.156253</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_8191278</td>\n      <td>0.125516</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Remove the target column from the submission DataFrame\nsub.drop('target', axis=1, inplace=True)\n\n# Merge the submission DataFrame with the prediction DataFrame on the image_name column\nsub = sub.merge(pred_df, on='image_name')\n\n# Save the merged DataFrame to a csv file without the index\nsub.to_csv('submission.csv', index=False)\n\n# Print the first 5 rows of the merged DataFrame\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-03T12:10:08.659811Z","iopub.execute_input":"2023-02-03T12:10:08.660240Z","iopub.status.idle":"2023-02-03T12:10:08.705401Z","shell.execute_reply.started":"2023-02-03T12:10:08.660197Z","shell.execute_reply":"2023-02-03T12:10:08.703242Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"     image_name    target\n0  ISIC_0052060  0.110213\n1  ISIC_0052349  0.166452\n2  ISIC_0058510  0.090335\n3  ISIC_0073313  0.060395\n4  ISIC_0073502  0.088133","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0052060</td>\n      <td>0.110213</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0052349</td>\n      <td>0.166452</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0058510</td>\n      <td>0.090335</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0073313</td>\n      <td>0.060395</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0073502</td>\n      <td>0.088133</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}
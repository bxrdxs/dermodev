{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":1,"source":["import re\n","import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from functools import partial\n","from kaggle_datasets import KaggleDatasets\n","from sklearn.model_selection import train_test_split\n","import tempfile\n","import matplotlib.pyplot as plt\n","\n","\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Device:', tpu.master())\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","except:\n","    strategy = tf.distribute.get_strategy()\n","print('Number of replicas:', strategy.num_replicas_in_sync)\n","    \n","print(tf.__version__)"],"outputs":[{"output_type":"stream","name":"stderr","text":["2023-01-26 09:22:41.964921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"]},{"output_type":"stream","name":"stdout","text":["Number of replicas: 1\n","2.4.1\n"]}],"metadata":{"execution":{"iopub.status.busy":"2023-01-26T09:22:41.284870Z","iopub.execute_input":"2023-01-26T09:22:41.285126Z","iopub.status.idle":"2023-01-26T09:22:46.920381Z","shell.execute_reply.started":"2023-01-26T09:22:41.285047Z","shell.execute_reply":"2023-01-26T09:22:46.919516Z"},"trusted":true}},{"cell_type":"code","execution_count":3,"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","GCS_PATH = KaggleDatasets().get_gcs_path()\n","BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n","IMAGE_SIZE = [1024, 1024]\n","IMAGE_RESIZE = [256, 256]"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-26T09:22:52.635453Z","iopub.execute_input":"2023-01-26T09:22:52.635747Z","iopub.status.idle":"2023-01-26T09:22:53.079507Z","shell.execute_reply.started":"2023-01-26T09:22:52.635715Z","shell.execute_reply":"2023-01-26T09:22:53.078773Z"},"trusted":true}},{"cell_type":"code","execution_count":4,"source":["trainingRecords, validationRecords = train_test_split(\n","    #returns a list of files matching the given pattern\n","    tf.io.gfile.glob(GCS_PATH + '/tfrecords/train*.tfrec'),\n","    test_size=0.1, random_state=5 \n",")\n","testRecords = tf.io.gfile.glob(GCS_PATH + '/tfrecords/test*.tfrec')\n","print('Train TFRecord Files:', len(trainingRecords))\n","print('Validation TFRecord Files:', len(validationRecords))\n","print('Test TFRecord Files:', len(testRecords))"],"outputs":[{"output_type":"stream","name":"stderr","text":["2023-01-26 09:22:56.174106: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'\".\n"]},{"output_type":"stream","name":"stdout","text":["Train TFRecord Files: 14\n","Validation TFRecord Files: 2\n","Test TFRecord Files: 16\n"]}],"metadata":{"execution":{"iopub.status.busy":"2023-01-26T09:22:55.896729Z","iopub.execute_input":"2023-01-26T09:22:55.897310Z","iopub.status.idle":"2023-01-26T09:22:56.500388Z","shell.execute_reply.started":"2023-01-26T09:22:55.897273Z","shell.execute_reply":"2023-01-26T09:22:56.499676Z"},"trusted":true}},{"cell_type":"markdown","source":["We need to know convert the images to tensors ( Tensors are similar to matrices and can have a specific shape and dimensionality)"],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["def transformAndNormalise(img):\n","    #image is transformed to RGB\n","    img = tf.image.decode_jpeg(img,channels=3)\n","    #Image is normalised\n","    img = tf.cast(img,tf.float32)/255\n","    #Reshaping the tensor\n","    img = tf.reshape(img,[*IMAGE_SIZE, 3])\n","    return img\n","    "],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-26T09:23:00.023326Z","iopub.execute_input":"2023-01-26T09:23:00.023647Z","iopub.status.idle":"2023-01-26T09:23:00.032483Z","shell.execute_reply.started":"2023-01-26T09:23:00.023612Z","shell.execute_reply":"2023-01-26T09:23:00.031798Z"},"trusted":true}},{"cell_type":"code","execution_count":6,"source":["def readTFRecord(example,labeled):\n","    #Defines the format of the data stored in TFRecord\n","    tfrecord_format = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"target\": tf.io.FixedLenFeature([], tf.int64)\n","    } if labeled else {\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n","    }\n","    example = tf.io.parse_single_example(example, tfrecord_format)\n","    image = transformAndNormalise(example['image'])\n","    if labeled:\n","        #if labelled return image and target as tuble\n","        label = tf.cast(example['target'], tf.int32)\n","        return image, label\n","    # if not labeled return iamge and image names as tuple\n","    idNumber = example['image_name']\n","    return image, idNumber"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-26T09:23:03.625318Z","iopub.execute_input":"2023-01-26T09:23:03.625604Z","iopub.status.idle":"2023-01-26T09:23:03.633713Z","shell.execute_reply.started":"2023-01-26T09:23:03.625571Z","shell.execute_reply":"2023-01-26T09:23:03.632718Z"},"trusted":true}},{"cell_type":"code","execution_count":7,"source":["def loadDataset(filenames,labeled=True, ordered = False):\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False # disable order, increase speed\n","    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(partial(readTFRecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n","    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n","    return dataset"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-26T09:23:06.960513Z","iopub.execute_input":"2023-01-26T09:23:06.961282Z","iopub.status.idle":"2023-01-26T09:23:06.966655Z","shell.execute_reply.started":"2023-01-26T09:23:06.961243Z","shell.execute_reply":"2023-01-26T09:23:06.965647Z"},"trusted":true}},{"cell_type":"code","execution_count":10,"source":["def dataAugmentation(image, label):\n","    \n","    #Flip image horizontally randomly\n","    image = tf.image.random_flip_left_right(image)\n","    #Resize image\n","    image = tf.image.resize(image, IMAGE_RESIZE)\n","    \n","    return image, label"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-25T20:10:41.591525Z","iopub.execute_input":"2023-01-25T20:10:41.592319Z","iopub.status.idle":"2023-01-25T20:10:41.598028Z","shell.execute_reply.started":"2023-01-25T20:10:41.592259Z","shell.execute_reply":"2023-01-25T20:10:41.596997Z"},"trusted":true}},{"cell_type":"code","execution_count":11,"source":["def resizeImage(image, label):\n","    image = tf.image.resize(image, IMAGE_RESIZE)\n","    return image, label"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-25T20:10:44.536212Z","iopub.execute_input":"2023-01-25T20:10:44.536548Z","iopub.status.idle":"2023-01-25T20:10:44.540750Z","shell.execute_reply.started":"2023-01-25T20:10:44.536515Z","shell.execute_reply":"2023-01-25T20:10:44.540130Z"},"trusted":true}},{"cell_type":"code","execution_count":12,"source":["def get_training_dataset():\n","    dataset = loadDataset(trainingRecords, labeled=True)\n","    dataset = dataset.map(dataAugmentation, num_parallel_calls=AUTOTUNE)\n","    dataset = dataset.repeat()\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTOTUNE)\n","    return dataset"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-25T20:10:46.441070Z","iopub.execute_input":"2023-01-25T20:10:46.441568Z","iopub.status.idle":"2023-01-25T20:10:46.447185Z","shell.execute_reply.started":"2023-01-25T20:10:46.441529Z","shell.execute_reply":"2023-01-25T20:10:46.446312Z"},"trusted":true}},{"cell_type":"code","execution_count":13,"source":["def get_validation_dataset(ordered=False):\n","    dataset = loadDataset(validationRecords, labeled=True, ordered=ordered)\n","    dataset = dataset.map(resizeImage, num_parallel_calls=AUTOTUNE)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.cache()\n","    dataset = dataset.prefetch(AUTOTUNE)\n","    return dataset"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-25T20:10:56.172142Z","iopub.execute_input":"2023-01-25T20:10:56.172468Z","iopub.status.idle":"2023-01-25T20:10:56.178013Z","shell.execute_reply.started":"2023-01-25T20:10:56.172434Z","shell.execute_reply":"2023-01-25T20:10:56.177165Z"},"trusted":true}},{"cell_type":"code","execution_count":14,"source":["def get_test_dataset(ordered=False):\n","    dataset = loadDataset(testRecords, labeled=False, ordered=ordered)\n","    dataset = dataset.map(resizeImage, num_parallel_calls=AUTOTUNE)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTOTUNE)\n","    return dataset"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-25T20:11:01.119192Z","iopub.execute_input":"2023-01-25T20:11:01.119507Z","iopub.status.idle":"2023-01-25T20:11:01.124938Z","shell.execute_reply.started":"2023-01-25T20:11:01.119478Z","shell.execute_reply":"2023-01-25T20:11:01.123993Z"},"trusted":true}},{"cell_type":"code","execution_count":15,"source":["def count_data_items(filenames):\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n","    return np.sum(n)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-25T20:11:03.754642Z","iopub.execute_input":"2023-01-25T20:11:03.755541Z","iopub.status.idle":"2023-01-25T20:11:03.760556Z","shell.execute_reply.started":"2023-01-25T20:11:03.755490Z","shell.execute_reply":"2023-01-25T20:11:03.759668Z"},"trusted":true}},{"cell_type":"code","execution_count":16,"source":["NUM_TRAINING_IMAGES = count_data_items(trainingRecords)\n","NUM_VALIDATION_IMAGES = count_data_items(validationRecords)\n","NUM_TEST_IMAGES = count_data_items(testRecords)\n","STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n","print(\n","    'Dataset: {} training images, {} validation images, {} unlabeled test images'.format(\n","        NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES\n","    )\n",")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset: 28984 training images, 4142 validation images, 10982 unlabeled test images\n"]}],"metadata":{"execution":{"iopub.status.busy":"2023-01-25T20:11:07.891919Z","iopub.execute_input":"2023-01-25T20:11:07.892657Z","iopub.status.idle":"2023-01-25T20:11:07.899154Z","shell.execute_reply.started":"2023-01-25T20:11:07.892623Z","shell.execute_reply":"2023-01-25T20:11:07.898206Z"},"trusted":true}},{"cell_type":"code","execution_count":17,"source":["#Reading the csv's\n","train_csv = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\n","test_csv = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-25T20:11:18.124932Z","iopub.execute_input":"2023-01-25T20:11:18.125394Z","iopub.status.idle":"2023-01-25T20:11:18.245508Z","shell.execute_reply.started":"2023-01-25T20:11:18.125346Z","shell.execute_reply":"2023-01-25T20:11:18.244607Z"},"trusted":true}},{"cell_type":"code","execution_count":18,"source":["# We are looking to get the disparity between malignant and benign images\n","totalImages = train_csv['target'].size\n","\n","malignant = np.count_nonzero(train_csv['target'])\n","benign = totalImages - malignant\n","\n","print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n","    totalImages, malignant, 100 * malignant / totalImages))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Examples:\n","    Total: 33126\n","    Positive: 584 (1.76% of total)\n","\n"]}],"metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:29:31.163192Z","iopub.execute_input":"2023-01-13T09:29:31.163506Z","iopub.status.idle":"2023-01-13T09:29:31.173849Z","shell.execute_reply.started":"2023-01-13T09:29:31.163470Z","shell.execute_reply":"2023-01-13T09:29:31.172902Z"},"trusted":true}},{"cell_type":"code","execution_count":19,"source":["trainDataset = get_training_dataset()\n","validationDataset = get_validation_dataset()\n","\n","trainDataset.take(1)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int32)>"]},"metadata":{},"execution_count":19}],"metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:29:35.529705Z","iopub.execute_input":"2023-01-13T09:29:35.529976Z","iopub.status.idle":"2023-01-13T09:29:35.866403Z","shell.execute_reply.started":"2023-01-13T09:29:35.529949Z","shell.execute_reply":"2023-01-13T09:29:35.865387Z"},"trusted":true}},{"cell_type":"code","execution_count":20,"source":["validationDataset.take(1)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int32)>"]},"metadata":{},"execution_count":20}],"metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:29:38.953906Z","iopub.execute_input":"2023-01-13T09:29:38.954539Z","iopub.status.idle":"2023-01-13T09:29:38.962488Z","shell.execute_reply.started":"2023-01-13T09:29:38.954502Z","shell.execute_reply":"2023-01-13T09:29:38.961394Z"},"trusted":true}},{"cell_type":"code","execution_count":21,"source":["images, labels = next(iter(trainDataset))"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:29:41.565101Z","iopub.execute_input":"2023-01-13T09:29:41.565711Z","iopub.status.idle":"2023-01-13T09:29:48.088187Z","shell.execute_reply.started":"2023-01-13T09:29:41.565672Z","shell.execute_reply":"2023-01-13T09:29:48.087188Z"},"trusted":true}},{"cell_type":"code","execution_count":28,"source":["def make_model(output_bias = None, metrics = None):    \n","    if output_bias is not None:\n","        output_bias = tf.keras.initializers.Constant(output_bias)\n","    # Creating a model with pre - trained weights from the EfficientNetB1 architecture\n","    \n","    base_model = tf.keras.applications.efficientnet.EfficientNetB1(input_shape=(*IMAGE_RESIZE, 3),\n","                                                include_top=False,\n","                                                weights='imagenet')\n","    #Freezing the base models weights\n","    base_model.trainable = False\n","    \n","    #Create a new sequential model\n","    model = tf.keras.Sequential([\n","        # Add the base model as the first layer\n","        base_model,\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        tf.keras.layers.Dense(8, activation='swish'),\n","        tf.keras.layers.Dense(1, activation='sigmoid',\n","                              bias_initializer=output_bias)\n","    ])\n","    \n","    model.compile(optimizer='adam',\n","                  loss='binary_crossentropy',\n","                  metrics=metrics)\n","    \n","    return model"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:32:49.431735Z","iopub.execute_input":"2023-01-13T09:32:49.432054Z","iopub.status.idle":"2023-01-13T09:32:49.440526Z","shell.execute_reply.started":"2023-01-13T09:32:49.432026Z","shell.execute_reply":"2023-01-13T09:32:49.439453Z"},"trusted":true}},{"cell_type":"code","execution_count":29,"source":["\n","\n","STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n","VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:32:54.680484Z","iopub.execute_input":"2023-01-13T09:32:54.680809Z","iopub.status.idle":"2023-01-13T09:32:54.685192Z","shell.execute_reply.started":"2023-01-13T09:32:54.680776Z","shell.execute_reply":"2023-01-13T09:32:54.684520Z"},"trusted":true}},{"cell_type":"code","execution_count":30,"source":["initial_bias = np.log([malignant/benign])\n","initial_bias"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-4.02038586])"]},"metadata":{},"execution_count":30}],"metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:32:56.464820Z","iopub.execute_input":"2023-01-13T09:32:56.465384Z","iopub.status.idle":"2023-01-13T09:32:56.471764Z","shell.execute_reply.started":"2023-01-13T09:32:56.465352Z","shell.execute_reply":"2023-01-13T09:32:56.470938Z"},"trusted":true}},{"cell_type":"code","execution_count":31,"source":["weight_for_0 = (1 / benign)*(totalImages)/2.0 \n","weight_for_1 = (1 / malignant)*(totalImages)/2.0\n","\n","class_weight = {0: weight_for_0, 1: weight_for_1}\n","\n","print('Weight for class 0: {:.2f}'.format(weight_for_0))\n","print('Weight for class 1: {:.2f}'.format(weight_for_1))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Weight for class 0: 0.51\n","Weight for class 1: 28.36\n"]}],"metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:32:58.633228Z","iopub.execute_input":"2023-01-13T09:32:58.633516Z","iopub.status.idle":"2023-01-13T09:32:58.639754Z","shell.execute_reply.started":"2023-01-13T09:32:58.633489Z","shell.execute_reply":"2023-01-13T09:32:58.638672Z"},"trusted":true}},{"cell_type":"code","execution_count":32,"source":["with strategy.scope():\n","    model = make_model(output_bias = initial_bias, metrics=tf.keras.metrics.AUC(name='auc'))"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:33:00.545512Z","iopub.execute_input":"2023-01-13T09:33:00.545824Z","iopub.status.idle":"2023-01-13T09:33:15.391046Z","shell.execute_reply.started":"2023-01-13T09:33:00.545796Z","shell.execute_reply":"2023-01-13T09:33:15.390101Z"},"trusted":true}},{"cell_type":"code","execution_count":34,"source":["checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"melanoma_model.h5\",\n","                                                    save_best_only=True)\n","\n","early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n","                                                     restore_best_weights=True)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:33:15.399473Z","iopub.execute_input":"2023-01-13T09:33:15.400018Z","iopub.status.idle":"2023-01-13T09:33:15.410333Z","shell.execute_reply.started":"2023-01-13T09:33:15.399973Z","shell.execute_reply":"2023-01-13T09:33:15.409431Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["#The purpose of this function is to ensure that the learning rate decreases over time, The techniques is called learning rate sheduling \n","#The learning rate decreases exponentially (The learn rate starts high and decreases quickly at the begining of training)\n","\n","def exponential_decay(lr0, s):\n","    def exponential_decay_fn(epoch):\n","        return lr0 * 0.1 **(epoch / s)\n","    return exponential_decay_fn\n","\n","exponential_decay_fn = exponential_decay(0.01, 20)\n","\n","lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["history = model.fit(\n","    trainDataset, epochs=100,\n","    steps_per_epoch=STEPS_PER_EPOCH,\n","    validation_data=validationDataset,\n","    validation_steps=VALID_STEPS,\n","    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n","    class_weight=class_weight\n",")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","226/226 [==============================] - 71s 230ms/step - loss: 0.9453 - auc: 0.4797 - val_loss: 0.5035 - val_auc: 0.4120\n","Epoch 2/100\n","226/226 [==============================] - 32s 141ms/step - loss: 0.7463 - auc: 0.4896 - val_loss: 0.5315 - val_auc: 0.4988\n","Epoch 3/100\n","226/226 [==============================] - 32s 141ms/step - loss: 0.7173 - auc: 0.5038 - val_loss: 0.4537 - val_auc: 0.4767\n","Epoch 4/100\n","226/226 [==============================] - 30s 131ms/step - loss: 0.7171 - auc: 0.5226 - val_loss: 0.6123 - val_auc: 0.5699\n","Epoch 5/100\n","226/226 [==============================] - 29s 131ms/step - loss: 0.7121 - auc: 0.5027 - val_loss: 0.6349 - val_auc: 0.4923\n","Epoch 6/100\n","226/226 [==============================] - 30s 132ms/step - loss: 0.7179 - auc: 0.4967 - val_loss: 0.6412 - val_auc: 0.5820\n","Epoch 7/100\n","226/226 [==============================] - 32s 144ms/step - loss: 0.7379 - auc: 0.4939 - val_loss: 0.4936 - val_auc: 0.4499\n","Epoch 8/100\n","226/226 [==============================] - 30s 133ms/step - loss: 0.7345 - auc: 0.4896 - val_loss: 0.8051 - val_auc: 0.5706\n","Epoch 9/100\n","226/226 [==============================] - 29s 128ms/step - loss: 0.7053 - auc: 0.5075 - val_loss: 0.6280 - val_auc: 0.4970\n","Epoch 10/100\n","226/226 [==============================] - 29s 131ms/step - loss: 0.7049 - auc: 0.4696 - val_loss: 0.6238 - val_auc: 0.6314\n","Epoch 11/100\n","196/226 [=========================>....] - ETA: 3s - loss: 0.7169 - auc: 0.4718"]}],"metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:33:17.944504Z","iopub.execute_input":"2023-01-13T09:33:17.944844Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["test_ds = get_test_dataset(ordered=True)\n","test_images_ds = test_ds.map(lambda image, idnum: image)\n","\n","print('predicting')\n","probabilities = model.predict(test_images_ds)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["sub = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\n","sub.head()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Unpack the id numbers from the test dataset\n","id_numbers = test_ds.map(lambda image, idnum: idnum)\n","\n","# Unbatch the id numbers\n","unbatched_ids = id_numbers.unbatch()\n","\n","# Get a batch of all the test images\n","all_ids = next(iter(unbatched_ids.batch(NUM_TEST_IMAGES)))\n","\n","# Convert the batch of ids to numpy array of strings\n","test_ids = all_ids.numpy().astype('U')\n","\n","print('Generating submission.csv file...')"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["pred_df = pd.DataFrame({'image_name': test_ids, 'target': np.concatenate(probabilities)})\n","pred_df.head()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Remove the target column from the submission DataFrame\n","sub.drop('target', axis=1, inplace=True)\n","\n","# Merge the submission DataFrame with the prediction DataFrame on the image_name column\n","sub = sub.merge(pred_df, on='image_name')\n","\n","# Save the merged DataFrame to a csv file without the index\n","sub.to_csv('submission.csv', index=False)\n","\n","# Print the first 5 rows of the merged DataFrame\n","sub.head()"],"outputs":[],"metadata":{}}]}